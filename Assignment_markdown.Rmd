```{r}
library(jsonlite)

cat("\014")  
rm(list=ls())


setwd("C:/Warwick/EC349/Assignment")

business_data <- stream_in(file("yelp_academic_dataset_business.json"))
checkin_data  <- stream_in(file("yelp_academic_dataset_checkin.json"))
tip_data  <- stream_in(file("yelp_academic_dataset_tip.json"))

```
```{r}
load("C:/Warwick/EC349/Assignment/yelp_review_small.Rda")
review_data <- review_data_small
rm(review_data_small)
```

```{r}
load("C:/Warwick/EC349/Assignment/yelp_user_small.Rda")
user_data <- user_data_small
rm(user_data_small)
```

Merging datasets:
```{r}
merged_df <- merge(review_data, business_data, by ="business_id", all.x= TRUE)
merged_df <- merge(merged_df, user_data, by ="user_id", all.x = TRUE)
```

```{r}
unique(merged_df$attributes$ByAppointmentOnly)
```

Making dummy variables for all the business attributes:
```{r}
merged_df$ByAppointmentOnly_dummy <- ifelse(is.na(merged_df$attributes$ByAppointmentOnly), NA, ifelse(merged_df$attributes$ByAppointmentOnly == "True", 1, 0))

merged_df$BusinessAcceptsCreditCards_dummy <- ifelse(is.na(merged_df$attributes$BusinessAcceptsCreditCards), NA, ifelse(merged_df$attributes$BusinessAcceptsCreditCards == "True", 1, 0))

merged_df$BikeParking_dummy <- ifelse(is.na(merged_df$attributes$BikeParking), NA, ifelse(merged_df$attributes$BikeParking == "True", 1, 0))

# Restaurants Price Range

merged_df$CoatCheck_dummy <- ifelse(is.na(merged_df$attributes$CoatCheck), NA, ifelse(merged_df$attributes$CoatCheck == "True", 1, 0))

merged_df$RestaurantsTakeOut_dummy <- ifelse(is.na(merged_df$attributes$RestaurantsTakeOut), NA, ifelse(merged_df$attributes$RestaurantsTakeOut == "True", 1, 0))

merged_df$RestaurantsDelivery_dummy <- ifelse(is.na(merged_df$attributes$RestaurantsDelivery), NA, ifelse(merged_df$attributes$RestaurantsDelivery == "True", 1, 0))

merged_df$Caters_dummy <- ifelse(is.na(merged_df$attributes$Caters), NA, ifelse(merged_df$attributes$Caters == "True", 1, 0))

#WiFi variable- come back

#Business Parking variable- come back

merged_df$WheelchairAccessible_dummy <- ifelse(is.na(merged_df$attributes$WheelchairAccessible), NA, ifelse(merged_df$attributes$WheelchairAccessible == "True", 1, 0))

merged_df$HappyHour_dummy <- ifelse(is.na(merged_df$attributes$HappyHour), NA, ifelse(merged_df$attributes$HappyHour == "True", 1, 0))

merged_df$OutdoorSeating_dummy <- ifelse(is.na(merged_df$attributes$OutdoorSeating), NA, ifelse(merged_df$attributes$OutdoorSeating == "True", 1, 0))

merged_df$HasTV_dummy <- ifelse(is.na(merged_df$attributes$HasTV), NA, ifelse(merged_df$attributes$HasTV == "True", 1, 0))

merged_df$RestaurantsReservations_dummy <- ifelse(is.na(merged_df$attributes$RestaurantsReservations), NA, ifelse(merged_df$attributes$RestaurantsReservations == "True", 1, 0))

merged_df$DogsAllowed_dummy <- ifelse(is.na(merged_df$attributes$DogsAllowed), NA, ifelse(merged_df$attributes$DogsAllowed == "True", 1, 0))

# Alcohol variable- come back

merged_df$GoodForKids_dummy <- ifelse(is.na(merged_df$attributes$GoodForKids), NA, ifelse(merged_df$attributes$GoodForKids == "True", 1, 0))

#Restaurants attire

# Ambience

merged_df$RestaurantsTableService_dummy <- ifelse(is.na(merged_df$attributes$RestaurantsTableService), NA, ifelse(merged_df$attributes$RestaurantsTableService == "True", 1, 0))

merged_df$RestaurantsGoodForGroups_dummy <- ifelse(is.na(merged_df$attributes$RestaurantsGoodForGroups), NA, ifelse(merged_df$attributes$RestaurantsGoodForGroups == "True", 1, 0))

merged_df$DriveThru_dummy <- ifelse(is.na(merged_df$attributes$DriveThru), NA, ifelse(merged_df$attributes$DriveThru == "True", 1, 0))

# Noise Level

# Good for meal

merged_df$BusinessAcceptsBitcoin_dummy <- ifelse(is.na(merged_df$attributes$BusinessAcceptsBitcoin), NA, ifelse(merged_df$attributes$BusinessAcceptsBitcoin == "True", 1, 0))

#smoking

#Music

merged_df$GoodForDancing_dummy <- ifelse(is.na(merged_df$attributes$GoodForDancing), NA, ifelse(merged_df$attributes$GoodForDancing == "True", 1, 0))

merged_df$AcceptsInsurance_dummy <- ifelse(is.na(merged_df$attributes$AcceptsInsurance), NA, ifelse(merged_df$attributes$AcceptsInsurance == "True", 1, 0))

# Best Nights

merged_df$BYOB_dummy <- ifelse(is.na(merged_df$attributes$BYOB), NA, ifelse(merged_df$attributes$BYOB == "True", 1, 0))

merged_df$Corkage_dummy <- ifelse(is.na(merged_df$attributes$Corkage), NA, ifelse(merged_df$attributes$Corkage == "True", 1, 0))

#BYOB Corkage

#Hair Specializes in

merged_df$Open24Hours_dummy <- ifelse(is.na(merged_df$attributes$Open24Hours), NA, ifelse(merged_df$attributes$Open24Hours == "True", 1, 0))

merged_df$RestaurantsCounterService_dummy <- ifelse(is.na(merged_df$attributes$RestaurantsCounterService), NA, ifelse(merged_df$attributes$RestaurantsCounterService == "True", 1, 0))

#Ages allowed

# Dietary restrictions
```

Making Dummy Variables for the states
```{r}
merged_df$state <- as.factor(merged_df$state)
```

```{r}
levels(merged_df$state)
```

```{r}
library(fastDummies)
merged_df <- dummy_cols(merged_df, select_columns = "state")
```

Deciding on business attributes or user variables:
```{r}
sum(rowSums(is.na(data.frame(merged_df$attributes.ByAppointmentOnly))) > 0)
```

```{r}
sum(rowSums(is.na(data.frame(merged_df$average_stars))) > 0)
```

```{r}
sum(rowSums(is.na(data.frame(merged_df[,c("attributes.ByAppointmentOnly","average_stars")]))) > 0)
```

```{r}
cor(merged_df$stars.x, merged_df$average_stars, use= "complete.obs")
```
Bar plot of mean stars given to businesses in different states
```{r}
statewise_stars <- aggregate(stars.x ~ state, data = merged_df, mean)

barplot(statewise_stars$stars.x, names.arg = statewise_stars$state, col = "skyblue", main = "Mean Stars by State", xlab = "State", ylab = "Mean Stars")
```

Bar graph of frequencies for different states:
```{r}
library(ggplot2)
ggplot(merged_df, aes(x = state)) +
  geom_bar(fill = "lightblue", color = "black") +
  labs(title = "Bar Plot of Frequencies",
       x = "State",
       y = "Frequency") +
  scale_y_continuous(labels = scales::comma_format(scale = 1e-3))
```
```{r}
sum(merged_df$state == "VT")
```

Choosing final Variables:
```{r}
cor_matrix <- cor(merged_df[,c("stars.x", "useful.x", "funny.x", "cool.x", "stars.y", "review_count.x", "is_open", "review_count.y", "useful.y", "funny.y", "cool.y", "fans", "average_stars", "compliment_hot", "compliment_more", "compliment_profile", "compliment_cute", "compliment_list", "compliment_note", "compliment_plain", "compliment_cool", "compliment_funny", "compliment_writer", "compliment_photos")], use= "complete.obs")
```

```{r}
cor_matrix_1 <- cor(merged_df[,c("stars.x", "useful.x", "funny.x", "cool.x")])

heatmap(cor_matrix_1, 
        col = colorRampPalette(c("white","red"))(50),
        main = "Correlation Heatmap",
        xlab = "Variables",
        ylab = "Variables")
```

```{r}
cor_matrix_2 <- cor(merged_df[,c("stars.x", "review_count.y", "useful.y", "funny.y", "cool.y", "fans")], use= "complete.obs")

heatmap(cor_matrix_2, 
        col = colorRampPalette(c("white","red"))(50),
        main = "Correlation Heatmap",
        xlab = "Variables",
        ylab = "Variables")
```
```{r}
cor_matrix_3 <- cor(merged_df[,c("stars.x","compliment_hot", "compliment_more", "compliment_profile", "compliment_cute", "compliment_list", "compliment_note", "compliment_plain", "compliment_cool", "compliment_funny", "compliment_writer", "compliment_photos")], use= "complete.obs")

heatmap(cor_matrix_3, 
        col = colorRampPalette(c("white","red"))(50),
        main = "Correlation Heatmap",
        xlab = "Variables",
        ylab = "Variables")
```

T-test to show significantly different means between businesses that are open v.s. not open
```{r}
t.test(stars.x ~ is_open, data = merged_df)
```

Making training datasets:
```{r}
set.seed(1)
train <- sample(1:nrow(merged_df), nrow(merged_df) - 10000)
merged_df_train <- merged_df[train,]
```

Making test datasets:
```{r}
merged_df_test <- merged_df[-train,]
```

Final dataframes:
```{r}
library(dplyr)
final_df_train <- select(merged_df_train, review_id, business_id, user_id, stars.x, useful.x, stars.y, review_count.x, is_open, review_count.y, average_stars, compliment_writer)

final_df_train <- na.omit(final_df_train)

final_df_test <- select(merged_df_test, review_id, business_id, user_id, stars.x, useful.x, stars.y, review_count.x, is_open, review_count.y, average_stars, compliment_writer)

final_df_test <- na.omit(final_df_test)
```

#Modelling

```{r}
lm_first <- lm(stars.x~useful.x+ stars.y+ review_count.x+ is_open+ review_count.y+ average_stars+ compliment_writer, data= final_df_train)
```

```{r}
summary(lm_first) 
```

```{r}
lm_first_predict<-predict(lm_first, newdata = final_df_test[,-4])
mse_lm <- mean((lm_first_predict-final_df_test$stars.x)^2)
print(paste("lm MSE: ", mse_lm))
```

```{r}
lm_first_predict_round <- data.frame(col1 = round(lm_first_predict))
lm_first_predict_round <- lm_first_predict_round %>%
  mutate(col2 = ifelse(col1>5,5,ifelse(col1<1, 1, col1)))

accuracy_percentage_lm <- (sum(lm_first_predict_round$col2 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_lm, "%"))
```

```{r}
matplot(1:100, cbind(lm_first_predict_round[1:100,2], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "Linear regression predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```


#Ridge Regression:

Building focussed datasets:
```{r}
shrinkage_train_x <- final_df_train[,-4]

shrinkage_train_y <- final_df_train[,c(1:4)]

shrinkage_test_x <- final_df_test[,-4]

shrinkage_test_y <- final_df_test[,c(1:4)]
```


Ridge Regression setting lamba:
```{r}
set.seed(1312)
library(glmnet)
grid <- 10^seq(10, -2, length = 100)
cv.ridge.mod <- cv.glmnet(as.matrix(shrinkage_train_x[,4:10]), as.matrix(shrinkage_train_y[,4]), alpha = 0, lambda = grid, thresh = 1e-12)
plot(cv.ridge.mod)
```

```{r}
optimal_lambda <- cv.ridge.mod$lambda.min
cat("Optimal Lambda:", optimal_lambda, "\n")
```

```{r}
ridge.mod <- glmnet(as.matrix(shrinkage_train_x[,4:10]), as.matrix(shrinkage_train_y[,4]), alpha = 0, lambda = optimal_lambda, thresh = 1e-12)
```

```{r}
ridge.pred <- predict(ridge.mod, s = optimal_lambda, newx = as.matrix(shrinkage_test_x[,c(4:10)]))
mse_ridge <- mean((ridge.pred - shrinkage_test_y$stars.x) ^ 2)
print(paste("ridge MSE", mse_ridge))
```

```{r}
colnames(ridge.pred)[1] <- "col1"

ridge_predict_round <- data.frame(col1 = round(ridge.pred))
ridge_predict_round <- ridge_predict_round %>%
  mutate(col2 = ifelse(col1>5,5,ifelse(col1<1, 1, col1)))

accuracy_percentage_ridge <- (sum(ridge_predict_round$col2 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_ridge, "%"))
```

```{r}
matplot(1:100, cbind(ridge_predict_round[1:100,2], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "Ridge regression predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```

#LASSO regression

Chosen lambda:
```{r}
library(glmnet)
set.seed(1312)
grid <- 10^seq(10, -2, length = 100)
cv.LASSO.mod <- cv.glmnet(as.matrix(shrinkage_train_x[,4:10]), as.matrix(shrinkage_train_y[,4]), alpha = 1, lambda = grid, thresh = 1e-12)
plot(cv.LASSO.mod)
```

```{r}
optimal_lambda <- cv.LASSO.mod$lambda.min
cat("Optimal Lambda:", optimal_lambda, "\n")
```

```{r}
LASSO.mod <- glmnet(as.matrix(shrinkage_train_x[,4:10]), as.matrix(shrinkage_train_y[,4]), alpha = 1, lambda = optimal_lambda, thresh = 1e-12)
```

```{r}
LASSO.pred <- predict(LASSO.mod, s = optimal_lambda, newx = as.matrix(shrinkage_test_x[,c(4:10)]))
mse_LASSO <- mean((LASSO.pred - shrinkage_test_y$stars.x) ^ 2)
print(paste("LASSO MSE: ", mse_LASSO))
```

```{r}
colnames(LASSO.pred)[1] <- "col1"

LASSO_predict_round <- data.frame(col1 = round(LASSO.pred))
LASSO_predict_round <- LASSO_predict_round %>%
  mutate(col2 = ifelse(col1>5,5,ifelse(col1<1, 1, col1)))

accuracy_percentage_LASSO <- (sum(LASSO_predict_round$col2 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_LASSO, "%"))
```

```{r}
matplot(1:100, cbind(LASSO_predict_round[1:100,2], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "LASSO regression predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```


Regression tree:
```{r}
library(rpart)
library(rpart.plot)
```

```{r}
set.seed(1312)
rpart_tree<-rpart(stars.x~useful.x+ stars.y+ review_count.x+ is_open+ review_count.y+ average_stars+ compliment_writer, data=final_df_train, cp=0.0001)
rpart.plot(rpart_tree)
```

```{r}
rpart_tree.pred <- predict(rpart_tree, newdata = final_df_test)
mse_rpart <- mean((rpart_tree.pred - final_df_test$stars.x) ^ 2)
print(paste("rpart MSE: ", mse_rpart))
```

```{r}
rpart_predict_round <- data.frame(col1 = round(rpart_tree.pred))
rpart_predict_round <- rpart_predict_round %>%
  mutate(col2 = ifelse(col1>5,5,ifelse(col1<1, 1, col1)))

accuracy_percentage_rpart <- (sum(rpart_predict_round$col2 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_rpart, "%"))
```

```{r}
matplot(1:100, cbind(rpart_predict_round[1:100,2], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "Regression Tree predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```

```{r}
set.seed(1312)
library(ipred)
bag <- bagging(stars.x~useful.x+ stars.y+ review_count.x+ is_open+ review_count.y+ average_stars+ compliment_writer, data = final_df_train, nbagg = 50, coob = TRUE, control = rpart.control(minsplit = 2, cp = 0.0001))
```

```{r}
bag
```

```{r}
bag.pred <- predict(bag, newdata = final_df_test)
mse_bagging <- mean((bag.pred - final_df_test$stars.x) ^ 2)
print(paste("bagging MSE: ", mse_bagging))
```

```{r}
bag_predict_round <- data.frame(col1 = round(bag.pred))
bag_predict_round <- bag_predict_round %>%
  mutate(col2 = ifelse(col1>5,5,ifelse(col1<1, 1, col1)))

accuracy_percentage_bag <- (sum(bag_predict_round$col2 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_bag, "%"))
```

```{r}
matplot(1:100, cbind(bag_predict_round[1:100,2], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "Bagging predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```
Random Forest
```{r}
library(randomForest)
set.seed(1312)
model_RF<-randomForest(stars.x~useful.x+ stars.y+ review_count.x+ is_open+ review_count.y+ average_stars+ compliment_writer, data = final_df_train, ntree=100, cp=0.0001)
```

```{r}
RF.pred = predict(model_RF,  newdata = final_df_test)
mse_RF <- mean((RF.pred - final_df_test$stars.x) ^ 2)
print(paste("RF MSE:", mse_RF))
```

```{r}
RF_predict_round <- data.frame(col1 = round(RF.pred))
RF_predict_round <- RF_predict_round %>%
  mutate(col2 = ifelse(col1==6,5,ifelse(col1==0, 1, col1)))

accuracy_percentage_RF <- (sum(RF_predict_round$col2 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_RF, "%"))
```

```{r}
matplot(1:100, cbind(RF_predict_round[1:100,2], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "Random Forest predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```

Boosting:
```{r}
set.seed(1312)
install.packages("gbm")
library(gbm)
boost <- gbm(stars.x~useful.x+ stars.y+ review_count.x+ is_open+ review_count.y+ average_stars+ compliment_writer, data = final_df_train, distribution = "gaussian", n.trees = 1000, shrinkage = 0.1, interaction.depth = 4, bag.fraction = 0.7, n.minobsinnode = 5)
```

```{r}
boost.pred <- predict(boost, newdata = final_df_test)
mse_boost <- mean((final_df_test$stars.x - boost.pred)^2)
print(paste("Boost MSE: ", mse_boost))
```

```{r}
boost_predict_round <- data.frame(col1 = round(boost.pred))
boost_predict_round <- boost_predict_round %>%
  mutate(col2 = ifelse(col1>5,5,ifelse(col1<1, 1, col1)))

accuracy_percentage_boost <- (sum(boost_predict_round$col2 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_boost, "%"))
```

```{r}
matplot(1:100, cbind(boost_predict_round[1:100,2], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "Boosting predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```

multinomial logistic regression
```{r}
library(nnet)

logistic.model <- multinom(as.factor(stars.x)~useful.x+ stars.y+ review_count.x+ is_open+ review_count.y+ average_stars+ compliment_writer, data = final_df_train)
```

```{r}
logistic.pred <- predict(logistic.model, newdata = final_df_test)
```
  
```{r}
logistic_predict <- data.frame(col1 = logistic.pred)

accuracy_percentage_logistic <- (sum(logistic_predict$col1 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_logistic, "%"))
```

```{r}
matplot(1:100, cbind(logistic_predict[1:100,], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "Logistic predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```

```{r}
rpart_tree_class<-rpart(as.factor(stars.x)~useful.x+ stars.y+ review_count.x+ is_open+ review_count.y+ average_stars+ compliment_writer, data=final_df_train, method= "class", cp = 0.0001)
rpart.plot(rpart_tree_class)
```

```{r}
rpart_class.pred <- predict(rpart_tree_class, newdata = final_df_test, type= "class")
```

```{r}
rpart_class_predict <- data.frame(rpart_class.pred)
colnames(rpart_class_predict)[1] <- "col1"

accuracy_percentage_rpart_class <- (sum(rpart_class_predict$col1 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_rpart_class, "%"))
```

```{r}
matplot(1:100, cbind(rpart_class_predict[1:100,], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "Classification Tree predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```

```{r}
set.seed(1312)
library(ipred)
bag_class <- bagging(as.factor(stars.x)~useful.x+ stars.y+ review_count.x+ is_open+ review_count.y+ average_stars+ compliment_writer, data = final_df_train, method= "class", nbagg = 50, coob = TRUE, control = rpart.control(minsplit = 2, cp = 0.0001))
```

```{r}
bag_class
```

```{r}
bag_class.pred <- predict(bag_class, newdata = final_df_test, type= "class")
```

```{r}
bag_class_predict <- data.frame(bag_class.pred)
colnames(bag_class_predict)[1] <- "col1"

accuracy_percentage_bag_class <- (sum(bag_class_predict$col1 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_bag_class, "%"))
```

```{r}
matplot(1:100, cbind(bag_class_predict[1:100,], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "Classification Bagging predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```

```{r}
library(randomForest)
set.seed(1312)
model_RF_class<-randomForest(as.factor(stars.x)~useful.x+ stars.y+ review_count.x+ is_open+ review_count.y+ average_stars+ compliment_writer, data = final_df_train, method = "class",ntree=100, cp=0.0001)
```

```{r}
RF_class.pred = predict(model_RF_class,  newdata = final_df_test, type= "class")
```

```{r}
RF_class_predict <- data.frame(RF_class.pred)
colnames(RF_class_predict)[1] <- "col1"

accuracy_percentage_RF_class <- (sum(RF_class_predict$col1 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_RF_class, "%"))
```

```{r}
matplot(1:100, cbind(RF_class_predict[1:100,], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "Classification Random Forest predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```

```{r}
install.packages("gbm")
library(gbm)
boost_class <- gbm(as.factor(stars.x)~useful.x+ stars.y+ review_count.x+ is_open+ review_count.y+ average_stars+ compliment_writer, data = final_df_train, distribution = "multinomial", n.trees = 1000, shrinkage = 0.01, interaction.depth = 4, bag.fraction = 0.7, n.minobsinnode = 5)
```


```{r}
boost_class.pred = predict(boost_class,  newdata = final_df_test, type = "response")
```

```{r}
boost_class_prob.pred<- data.frame(boost_class.pred)

new_col_names <- c(1, 2, 3, 4, 5)

colnames(boost_class_prob.pred) <- new_col_names

boost_class_prob.pred$col1 <- colnames(boost_class_prob.pred)[max.col(boost_class_prob.pred, ties.method = "first")]

boost_class_prob.pred <- data.frame(col1 = boost_class_prob.pred[,6])
```

```{r}
boost_class_predict <- boost_class_prob.pred

accuracy_percentage_boost_class <- (sum(boost_class_predict$col1 == final_df_test$stars.x)/nrow(final_df_test))*100
print(paste("Accuracy Percentage:", accuracy_percentage_boost_class, "%"))
```

```{r}
matplot(1:100, cbind(boost_class_predict[1:100,], data.frame(final_df_test$stars.x)[1:100,]), type = "l", lty = 1, 
        col = c("red", "blue"), xlab = "First 100 test data points", 
        ylab = "Stars", main = "Classification Random Forest predictions v.s. observed stars")
legend("topright", legend = c("Prediction", "actual"), 
       col = c("red", "blue"), 
       lty = 1)
```